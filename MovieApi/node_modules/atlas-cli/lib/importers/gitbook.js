import fs from 'fs-promise';
import path from 'path';
import mime from 'mime';
import FormData from 'form-data';
import gitbookParsers from 'gitbook-parsers';
import readlineSync from 'readline-sync';
import _ from 'lodash';
import asyncReplace from '../utils/asyncReplace';

const IMAGE_REGEX = /(!\[.*?\]\()(.+?)(\))/g;

const getCollectionName = (defaultName) => {
  const name = readlineSync.question(`Collection name: (${defaultName}) `);
  return name || defaultName;
};

const readfile = async (filePath) => {
  const content = await fs.readFile(filePath, {
    encoding: 'utf-8',
  });
  return content;
};

const createCollection = async (client, name) => {
  const collection = await client.post('/collections.create', {
    name,
    type: 'atlas',
  });
  return collection;
};

const processFile = async (client, file, options) => {
  console.log(`Saving: ${file.title} (${file.path})`);

  // Read file
  let content;
  try {
    content = await readfile(path.join(process.cwd(), file.path));
  } catch (e) {
    console.log('Warning: No content for file, saving empty document');
    content = `# ${file.title}\n\n`;
    return;
  }

  // Upload local images to S3
  content = await asyncReplace(content, IMAGE_REGEX, async (whole, start, filePath, end) => {
    // Don't modify images with urls, only local files
    if (filePath.match(/^https?:\/\//g)) return whole;

    console.log(`Uploading image: ${filePath}`);
    let imageTag = whole;
    const filename = filePath.split('/').pop();

    // Remove leading `/`
    const filePathParts = filePath.split('/');
    _.remove(filePathParts, part => part === '');
    filePath = filePathParts.join('/');

    try {
      // Get upload access token
      const kind = mime.lookup(filePath);
      const size = fs.statSync(filePath).size;
      const uploadParams = await client.post('/user.s3Upload', {
        filename,
        kind,
        size,
      });

      const form = new FormData();
      // Add params
      _.map(uploadParams.data.form, (value, key) => {
        form.append(key, value);
      });
      // Add file
      form.append('file', fs.createReadStream(filePath));

      // Upload to S3
      await new Promise((resolve, reject) => {
        form.submit(uploadParams.data.uploadUrl, (err, res) => {
          if (err) reject(err);
          resolve(res);
        });
      });

      imageTag = `${start}${uploadParams.data.asset.url}${end}`;
    } catch (e) {
      console.error(e);
    }

    return imageTag;
  });

  // Create document
  let document;
  try {
    document = await client.post('/documents.create', {
      title: file.title,
      text: content,
      collection: options.collection.id,
      parentDocument: options.parentDocumentId,
    });
  } catch (e) {
    console.error(e);
    return;
  }

  // Process children recursively
  for (const article of file.articles) {
    await processFile(client, article, {
      collection: options.collection,
      parentDocumentId: document.data.id,
    });
  }
};

const gitbookImporter = async (client, _options) => {
  let config;
  try {
    const configFileContent = await fs.readFile(path.join(process.cwd(), 'book.json'));
    config = JSON.parse(configFileContent);
  } catch (e) {
    console.error('Error reading config file (book.json)');
    return;
  }

  const summaryFile = path.join(process.cwd(), config.structure.summary);
  const content = await readfile(summaryFile);
  const parser = gitbookParsers.getForFile(summaryFile);

  try {
    const summary = await parser.summary(content);

    const collectionName = getCollectionName(config.title || 'gitbook');
    const collection = await createCollection(client, collectionName);

    for (const file of summary.chapters) {
      await processFile(client, file, {
        collection: collection.data,
        parentDocumentId: collection.data.navigationTree.id,
      });
    }
  } catch (e) {
    console.error(e);
    return;
  }
};

export default gitbookImporter;
